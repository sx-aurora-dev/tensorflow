// RUN: hlo_to_llvm_ir %s | FileCheck %s

// CHECK-LABEL: entry:
// CHECK:         %[[VAL_0:.*]] = getelementptr inbounds i8, i8* %[[VAL_1:.*]], i64 0
// CHECK:         %[[VAL_2:.*]] = bitcast i8* %[[VAL_0]] to [3 x [3 x i32]]*
// CHECK:         %[[VAL_3:.*]] = getelementptr inbounds i8, i8* %[[VAL_1]], i64 0
// CHECK:         %[[VAL_4:.*]] = bitcast i8* %[[VAL_3]] to [3 x [3 x i32]]*
// CHECK:         %[[VAL_5:.*]] = getelementptr inbounds i8, i8* %[[VAL_6:.*]], i64 0
// CHECK:         %[[VAL_7:.*]] = bitcast i8* %[[VAL_5]] to [3 x [3 x i32]]*
// CHECK:         %[[VAL_8:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !8
// CHECK:         %[[VAL_9:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !9
// CHECK:         %[[VAL_10:.*]] = mul nuw nsw i32 %[[VAL_8]], 9
// CHECK:         %[[VAL_11:.*]] = add nuw nsw i32 %[[VAL_10]], %[[VAL_9]]
// CHECK:         %[[VAL_12:.*]] = icmp ult i32 %[[VAL_11]], 9
// CHECK:         call void @llvm.assume(i1 %[[VAL_12]])
// CHECK:         %[[VAL_13:.*]] = udiv i32 %[[VAL_11]], 1
// CHECK:         %[[VAL_14:.*]] = urem i32 %[[VAL_13]], 3
// CHECK:         %[[VAL_15:.*]] = udiv i32 %[[VAL_11]], 3
// CHECK:         %[[VAL_16:.*]] = icmp ult i32 %[[VAL_11]], 9
// CHECK:         br i1 %[[VAL_16]], label %[[VAL_17:.*]], label %[[VAL_18:.*]]
// CHECK:       operand.in_bounds-after:                          ; preds = %[[VAL_17]], %[[VAL_19:.*]]
// CHECK:         ret void
// CHECK:       operand.in_bounds-true:                           ; preds = %[[VAL_19]]
// CHECK:         %[[VAL_20:.*]] = bitcast [3 x [3 x i32]]* %[[VAL_2]] to i32*
// CHECK:         %[[VAL_21:.*]] = getelementptr inbounds i32, i32* %[[VAL_20]], i32 %[[VAL_11]]
// CHECK:         %[[VAL_22:.*]] = load i32, i32* %[[VAL_21]], align 4, !invariant.load !10
// CHECK:         %[[VAL_23:.*]] = bitcast [3 x [3 x i32]]* %[[VAL_4]] to i32*
// CHECK:         %[[VAL_24:.*]] = getelementptr inbounds i32, i32* %[[VAL_23]], i32 %[[VAL_11]]
// CHECK:         %[[VAL_25:.*]] = load i32, i32* %[[VAL_24]], align 4, !invariant.load !10
// CHECK:         %[[VAL_26:.*]] = add i32 %[[VAL_22]], %[[VAL_25]]
// CHECK:         %[[VAL_27:.*]] = bitcast [3 x [3 x i32]]* %[[VAL_7]] to i32*
// CHECK:         %[[VAL_28:.*]] = getelementptr inbounds i32, i32* %[[VAL_27]], i32 %[[VAL_11]]
// CHECK:         store i32 %[[VAL_26]], i32* %[[VAL_28]], align 4
// CHECK:         br label %[[VAL_18]]
// CHECK:       entry:
// CHECK:         %[[VAL_29:.*]] = getelementptr inbounds i8, i8* %[[VAL_30:.*]], i64 0
// CHECK:         %[[VAL_31:.*]] = bitcast i8* %[[VAL_29]] to [2 x [3 x i32]]*
// CHECK:         %[[VAL_32:.*]] = getelementptr inbounds i8, i8* %[[VAL_30]], i64 0
// CHECK:         %[[VAL_33:.*]] = bitcast i8* %[[VAL_32]] to [2 x [3 x i32]]*
// CHECK:         %[[VAL_34:.*]] = getelementptr inbounds i8, i8* %[[VAL_35:.*]], i64 0
// CHECK:         %[[VAL_36:.*]] = bitcast i8* %[[VAL_34]] to [2 x [3 x i32]]*
// CHECK:         %[[VAL_37:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !8
// CHECK:         %[[VAL_38:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !11
// CHECK:         %[[VAL_39:.*]] = mul nuw nsw i32 %[[VAL_37]], 3
// CHECK:         %[[VAL_40:.*]] = add nuw nsw i32 %[[VAL_39]], %[[VAL_38]]
// CHECK:         %[[VAL_41:.*]] = icmp ult i32 %[[VAL_40]], 3
// CHECK:         call void @llvm.assume(i1 %[[VAL_41]])
// CHECK:         %[[VAL_42:.*]] = mul nuw nsw i32 %[[VAL_40]], 2
// CHECK:         %[[VAL_43:.*]] = udiv i32 %[[VAL_42]], 1
// CHECK:         %[[VAL_44:.*]] = urem i32 %[[VAL_43]], 3
// CHECK:         %[[VAL_45:.*]] = udiv i32 %[[VAL_42]], 3
// CHECK:         %[[VAL_46:.*]] = add nuw nsw i32 %[[VAL_42]], 1
// CHECK:         %[[VAL_47:.*]] = udiv i32 %[[VAL_46]], 1
// CHECK:         %[[VAL_48:.*]] = urem i32 %[[VAL_47]], 3
// CHECK:         %[[VAL_49:.*]] = udiv i32 %[[VAL_46]], 3
// CHECK:         %[[VAL_50:.*]] = icmp ult i32 %[[VAL_42]], 6
// CHECK:         br i1 %[[VAL_50]], label %[[VAL_51:.*]], label %[[VAL_52:.*]]
// CHECK:       updates.in_bounds-after:                          ; preds = %[[VAL_51]], %[[VAL_53:.*]]
// CHECK:         ret void
// CHECK:       updates.in_bounds-true:                           ; preds = %[[VAL_53]]
// CHECK:         %[[VAL_54:.*]] = bitcast [2 x [3 x i32]]* %[[VAL_31]] to i32*
// CHECK:         %[[VAL_55:.*]] = getelementptr inbounds i32, i32* %[[VAL_54]], i32 %[[VAL_42]]
// CHECK:         %[[VAL_56:.*]] = load i32, i32* %[[VAL_55]], align 4, !invariant.load !10
// CHECK:         %[[VAL_57:.*]] = bitcast [2 x [3 x i32]]* %[[VAL_33]] to i32*
// CHECK:         %[[VAL_58:.*]] = getelementptr inbounds i32, i32* %[[VAL_57]], i32 %[[VAL_42]]
// CHECK:         %[[VAL_59:.*]] = load i32, i32* %[[VAL_58]], align 4, !invariant.load !10
// CHECK:         %[[VAL_60:.*]] = add i32 %[[VAL_56]], %[[VAL_59]]
// CHECK:         %[[VAL_61:.*]] = bitcast [2 x [3 x i32]]* %[[VAL_36]] to i32*
// CHECK:         %[[VAL_62:.*]] = getelementptr inbounds i32, i32* %[[VAL_61]], i32 %[[VAL_42]]
// CHECK:         store i32 %[[VAL_60]], i32* %[[VAL_62]], align 4
// CHECK:         %[[VAL_63:.*]] = bitcast [2 x [3 x i32]]* %[[VAL_31]] to i32*
// CHECK:         %[[VAL_64:.*]] = getelementptr inbounds i32, i32* %[[VAL_63]], i32 %[[VAL_46]]
// CHECK:         %[[VAL_65:.*]] = load i32, i32* %[[VAL_64]], align 4, !invariant.load !10
// CHECK:         %[[VAL_66:.*]] = bitcast [2 x [3 x i32]]* %[[VAL_33]] to i32*
// CHECK:         %[[VAL_67:.*]] = getelementptr inbounds i32, i32* %[[VAL_66]], i32 %[[VAL_46]]
// CHECK:         %[[VAL_68:.*]] = load i32, i32* %[[VAL_67]], align 4, !invariant.load !10
// CHECK:         %[[VAL_69:.*]] = add i32 %[[VAL_65]], %[[VAL_68]]
// CHECK:         %[[VAL_70:.*]] = bitcast [2 x [3 x i32]]* %[[VAL_36]] to i32*
// CHECK:         %[[VAL_71:.*]] = getelementptr inbounds i32, i32* %[[VAL_70]], i32 %[[VAL_46]]
// CHECK:         store i32 %[[VAL_69]], i32* %[[VAL_71]], align 4
// CHECK:         br label %[[VAL_52]]
// CHECK:       entry:
// CHECK:         %[[VAL_72:.*]] = getelementptr inbounds i8, i8* %[[VAL_73:.*]], i64 0
// CHECK:         %[[VAL_74:.*]] = bitcast i8* %[[VAL_72]] to [2 x i32]*
// CHECK:         %[[VAL_75:.*]] = getelementptr inbounds i8, i8* %[[VAL_73]], i64 0
// CHECK:         %[[VAL_76:.*]] = bitcast i8* %[[VAL_75]] to [2 x i32]*
// CHECK:         %[[VAL_77:.*]] = getelementptr inbounds i8, i8* %[[VAL_78:.*]], i64 64
// CHECK:         %[[VAL_79:.*]] = bitcast i8* %[[VAL_77]] to [2 x i32]*
// CHECK:         %[[VAL_80:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !8
// CHECK:         %[[VAL_81:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !8
// CHECK:         %[[VAL_82:.*]] = mul nuw nsw i32 %[[VAL_80]], 1
// CHECK:         %[[VAL_83:.*]] = add nuw nsw i32 %[[VAL_82]], %[[VAL_81]]
// CHECK:         %[[VAL_84:.*]] = icmp ult i32 %[[VAL_83]], 1
// CHECK:         call void @llvm.assume(i1 %[[VAL_84]])
// CHECK:         %[[VAL_85:.*]] = mul nuw nsw i32 %[[VAL_83]], 2
// CHECK:         %[[VAL_86:.*]] = udiv i32 %[[VAL_85]], 1
// CHECK:         %[[VAL_87:.*]] = add nuw nsw i32 %[[VAL_85]], 1
// CHECK:         %[[VAL_88:.*]] = udiv i32 %[[VAL_87]], 1
// CHECK:         %[[VAL_89:.*]] = icmp ult i32 %[[VAL_85]], 2
// CHECK:         br i1 %[[VAL_89]], label %[[VAL_90:.*]], label %[[VAL_91:.*]]
// CHECK:       indices.in_bounds-after:                          ; preds = %[[VAL_90]], %[[VAL_92:.*]]
// CHECK:         ret void
// CHECK:       indices.in_bounds-true:                           ; preds = %[[VAL_92]]
// CHECK:         %[[VAL_93:.*]] = bitcast [2 x i32]* %[[VAL_74]] to i32*
// CHECK:         %[[VAL_94:.*]] = getelementptr inbounds i32, i32* %[[VAL_93]], i32 %[[VAL_85]]
// CHECK:         %[[VAL_95:.*]] = load i32, i32* %[[VAL_94]], align 4, !invariant.load !10
// CHECK:         %[[VAL_96:.*]] = bitcast [2 x i32]* %[[VAL_76]] to i32*
// CHECK:         %[[VAL_97:.*]] = getelementptr inbounds i32, i32* %[[VAL_96]], i32 %[[VAL_85]]
// CHECK:         %[[VAL_98:.*]] = load i32, i32* %[[VAL_97]], align 4, !invariant.load !10
// CHECK:         %[[VAL_99:.*]] = add i32 %[[VAL_95]], %[[VAL_98]]
// CHECK:         %[[VAL_100:.*]] = bitcast [2 x i32]* %[[VAL_79]] to i32*
// CHECK:         %[[VAL_101:.*]] = getelementptr inbounds i32, i32* %[[VAL_100]], i32 %[[VAL_85]]
// CHECK:         store i32 %[[VAL_99]], i32* %[[VAL_101]], align 4
// CHECK:         %[[VAL_102:.*]] = bitcast [2 x i32]* %[[VAL_74]] to i32*
// CHECK:         %[[VAL_103:.*]] = getelementptr inbounds i32, i32* %[[VAL_102]], i32 %[[VAL_87]]
// CHECK:         %[[VAL_104:.*]] = load i32, i32* %[[VAL_103]], align 4, !invariant.load !10
// CHECK:         %[[VAL_105:.*]] = bitcast [2 x i32]* %[[VAL_76]] to i32*
// CHECK:         %[[VAL_106:.*]] = getelementptr inbounds i32, i32* %[[VAL_105]], i32 %[[VAL_87]]
// CHECK:         %[[VAL_107:.*]] = load i32, i32* %[[VAL_106]], align 4, !invariant.load !10
// CHECK:         %[[VAL_108:.*]] = add i32 %[[VAL_104]], %[[VAL_107]]
// CHECK:         %[[VAL_109:.*]] = bitcast [2 x i32]* %[[VAL_79]] to i32*
// CHECK:         %[[VAL_110:.*]] = getelementptr inbounds i32, i32* %[[VAL_109]], i32 %[[VAL_87]]
// CHECK:         store i32 %[[VAL_108]], i32* %[[VAL_110]], align 4
// CHECK:         br label %[[VAL_91]]
// CHECK:       entry:
// CHECK:         %[[VAL_111:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_112:.*]] = getelementptr inbounds i8, i8* %[[VAL_113:.*]], i64 64
// CHECK:         %[[VAL_114:.*]] = bitcast i8* %[[VAL_112]] to [2 x i32]*
// CHECK:         %[[VAL_115:.*]] = getelementptr inbounds i8, i8* %[[VAL_113]], i64 0
// CHECK:         %[[VAL_116:.*]] = bitcast i8* %[[VAL_115]] to [2 x [3 x i32]]*
// CHECK:         %[[VAL_117:.*]] = getelementptr inbounds i8, i8* %[[VAL_118:.*]], i64 0
// CHECK:         %[[VAL_119:.*]] = bitcast i8* %[[VAL_117]] to [3 x [3 x i32]]*
// CHECK:         %[[VAL_120:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !8
// CHECK:         %[[VAL_121:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !12
// CHECK:         %[[VAL_122:.*]] = mul nuw nsw i32 %[[VAL_120]], 6
// CHECK:         %[[VAL_123:.*]] = add nuw nsw i32 %[[VAL_122]], %[[VAL_121]]
// CHECK:         %[[VAL_124:.*]] = icmp ult i32 %[[VAL_123]], 6
// CHECK:         call void @llvm.assume(i1 %[[VAL_124]])
// CHECK:         %[[VAL_125:.*]] = udiv i32 %[[VAL_123]], 1
// CHECK:         %[[VAL_126:.*]] = urem i32 %[[VAL_125]], 3
// CHECK:         %[[VAL_127:.*]] = udiv i32 %[[VAL_123]], 3
// CHECK:         %[[VAL_128:.*]] = icmp ult i32 %[[VAL_123]], 6
// CHECK:         br i1 %[[VAL_128]], label %[[VAL_129:.*]], label %[[VAL_130:.*]]
// CHECK:       scatter.in_bounds-after:                          ; preds = %[[VAL_131:.*]], %[[VAL_132:.*]]
// CHECK:         ret void
// CHECK:       scatter.in_bounds-true:                           ; preds = %[[VAL_132]]
// CHECK:         %[[VAL_133:.*]] = getelementptr inbounds [2 x i32], [2 x i32]* %[[VAL_114]], i32 0, i32 %[[VAL_127]]
// CHECK:         %[[VAL_134:.*]] = load i32, i32* %[[VAL_133]], align 4, !invariant.load !10
// CHECK:         %[[VAL_135:.*]] = add i32 0, %[[VAL_134]]
// CHECK:         %[[VAL_136:.*]] = icmp ult i32 %[[VAL_134]], 3
// CHECK:         %[[VAL_137:.*]] = and i1 true, %[[VAL_136]]
// CHECK:         br i1 %[[VAL_137]], label %[[VAL_138:.*]], label %[[VAL_131]]
// CHECK:       scatter.in_bounds-after3:                         ; preds = %[[VAL_138]], %[[VAL_129]]
// CHECK:         br label %[[VAL_130]]
// CHECK:       scatter.in_bounds-true2:                          ; preds = %[[VAL_129]]
// CHECK:         %[[VAL_139:.*]] = getelementptr inbounds [3 x [3 x i32]], [3 x [3 x i32]]* %[[VAL_119]], i32 0, i32 %[[VAL_135]], i32 %[[VAL_126]]
// CHECK:         %[[VAL_140:.*]] = bitcast [2 x [3 x i32]]* %[[VAL_116]] to i32*
// CHECK:         %[[VAL_141:.*]] = getelementptr inbounds i32, i32* %[[VAL_140]], i32 %[[VAL_123]]
// CHECK:         %[[VAL_142:.*]] = load i32, i32* %[[VAL_141]], align 4, !invariant.load !10
// CHECK:         store i32 %[[VAL_142]], i32* %[[VAL_111]], align 4
// CHECK:         %[[VAL_143:.*]] = load i32, i32* %[[VAL_111]], align 4
// CHECK:         store atomic i32 %[[VAL_143]], i32* %[[VAL_139]] unordered, align 4
// CHECK:         br label %[[VAL_131]]

HloModule TensorFlowScatterV1

update_s32 (lhs: s32[], rhs: s32[]) -> s32[] {
  lhs = s32[] parameter(0)
  ROOT rhs = s32[] parameter(1)
}

ENTRY main {
  p0 = s32[3,3] parameter(0)
  operand = s32[3,3] add(p0, p0)
  p1 = s32[2] parameter(1)
  indices = s32[2] add(p1, p1)
  p2 = s32[2,3] parameter(2)
  updates = s32[2,3] add(p2, p2)
  ROOT scatter = s32[3,3] scatter(operand, indices, updates),
      to_apply=update_s32,
      update_window_dims={1},
      inserted_window_dims={0},
      scatter_dims_to_operand_dims={0},
      index_vector_dim=1
}
